\documentclass[11pt]{article}
\usepackage{../acl2016}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here
%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\usepackage[breaklinks, colorlinks, linkcolor=black, urlcolor=black, citecolor=black, draft]{hyperref}
\usepackage{natbib}
\usepackage{times}
\usepackage{latexsym}
% \setlength\titlebox{7.5cm}    % Expanding the titlebox

%%% Custom additions %%%
\usepackage{url}
\usepackage[leqno, fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{qtree}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{pgfplots}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{stmaryrd}
\usepackage{gb4e}

\newcommand\todo[1]{\textcolor{blue}{\textbf{TODO:} #1}}
\newcommand\result[1]{\textcolor{red}{\textbf{RESULT NEEDED:} #1}}
\newcommand\question[1]{\textcolor{orange}{\textbf{OPEN QUESTION:} #1}}

\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{bmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{bmatrix}
        \fi
}

\newcommand{\shift}{\textsc{shift}}
\newcommand{\reduce}{\textsc{reduce}}
 
\def\ii#1{\textit{#1}}
\newcommand{\word}[1]{\emph{#1}}
\newcommand{\fulllabel}[2]{\b{#1}\newline\textsc{#2}}

\newcommand{\snli}[3]{{\vspace{0.25em}
{\small \setlength{\parindent}{0.6em} \hangindent=1.2em  \textbf{Premise:} #1\par}\vspace{0.25em}
{\small \setlength{\parindent}{0.6em} \hangindent=1.2em   \textbf{Hypothesis:} #2\par}\vspace{0.25em}
{\small \setlength{\parindent}{0.6em}  \textbf{Label:} #3\par}
}}


\noautomath

\title{Supplement to:\\A Fast Unified Model for Parsing and Sentence Understanding} 

     \author{}
%    \author{
%    Samuel R.\ Bowman$^{1,2,5,}$\thanks{~\,The first two authors contributed equally.} \\
%    \texttt{\small sbowman@stanford.edu} \\
%    \And
%    Jon Gauthier$^{2,3,5,*}$ \\
%    \texttt{\small jgauthie@stanford.edu} \\
%    \And
%    Abhinav Rastogi$^{4,5}$ \\
%    \texttt{\small arastogi@stanford.edu} \\
%    \AND
%    Raghav Gupta$^{6}$ \\
%    \texttt{\small rgupta93@stanford.edu} \\
%    \And
%    Christopher D.\ Manning$^{1,2,5,6}$\\
%    \texttt{\small manning@stanford.edu}\\
%    \And
%    Christopher Potts$^{1}$\\
%    \texttt{\small cgpotts@stanford.edu}
%    \AND\\[-3ex]
%    {$^{1}$Stanford Linguistics\quad
%    $^{2}$Stanford NLP Group\quad
%    $^{3}$Stanford Symbolic Systems}\\
%    {$^{4}$Stanford Electrical Engineering\quad
%    $^{5}$Stanford AI Lab\quad
%    $^{6}$Stanford Computer Science}
%    }

\date{}


\begin{document}
\maketitle


\begin{table*}[h!]\small
\begin{center}
\begin{tabular}{lrlrrrr}
\toprule
Param.     & Range & Strategy        & RNN       & SPINN-PI-NT   & SPINN-PI  & SPINN \\
\midrule 
Initial LR & 2e-4--2e-2 & \textsc{log} & 5e-3  & 3e-4 & 7e-3  & 2e-3\\
L2 regularization $\lambda$ & 8e-7--3e-5   & \textsc{log} & 4e-6  & 3e-6   & 2e-5  & 3e-5\\
Transition cost $\alpha$  & 0.5--4.0 & \textsc{lin} & --- & --- & ---  & 3.9    \\
Embedding transformation dropout keep rate & 80--95\% & \textsc{lin} & --- & 83\% & 92\%  & 86\%\\
Classifier MLP dropout keep rate & 80--95\% & \textsc{lin} & 94\%  & 94\%   & 93\%  & 94\%\\
Tracking LSTM size $D_\text{tracking}$ & 24--128 & \textsc{log} & --- & --- & 61  & 79\\
Classifier MLP layers & 1--3 & \textsc{lin} & 2 & 2 & 2 & 1\\
\bottomrule
\end{tabular}
\end{center}
 
\caption{
\label{tab:hyperparams}
Hyperparameter ranges and values. \ii{Range} shows the hyperparameter ranges explored during random search. \ii{Strategy} indicates whether sampling from the range was uniform, or log--uniform.
}
\end{table*}


\section{Hyperparameters}\label{sec:hyperparams}


We use random search to tune the hyperparameters of the model, setting the ranges for search for each hyperparameter heuristically (and validating the reasonableness of the ranges on the development set), and then launching eight copies of each experiment each with newly sampled hyperparameters from those ranges. Table~\ref{tab:hyperparams} (on the following page) shows the hyperparameters used in the best run of each model.


\end{document}
